"""
Hypothesis specification data models.

Design principles:
- Immutable dataclasses for all specifications
- JSON-serializable for database storage
- Clear separation between parent hypothesis and enumerated variants
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, FrozenSet, Tuple
from enum import Enum
import hashlib
import json


class SamplingClock(Enum):
    """
    Native timescale for signal formation.

    Determines how data is sampled and aggregated.
    """
    INTRADAY = "intraday"       # 5s/1m/5m etc (sub-daily)
    DAILY = "daily"             # EOD snapshots
    EVENT_TIME = "event_time"   # WPSR, earnings, scheduled events


class TargetType(Enum):
    """
    What the signal is trying to predict.

    Different target types measure different aspects of predictive content.
    """
    FORWARD_RETURN = "forward_return"   # Δprice / price
    FORWARD_CHANGE = "forward_change"   # Δsignal (shock response)
    CARRY_RETURN = "carry_return"       # Realized carry P&L


class Direction(Enum):
    """
    Expected relationship between signal and target.

    UNKNOWN is the default - scorer determines from data.
    """
    UNKNOWN = "unknown"         # Let scorer determine from data
    PROCYC = "procyc"           # Signal high → return positive (trend)
    CONTRACYC = "contracyc"     # Signal high → return negative (MR)


class NormalizationType(Enum):
    """
    How to normalize the raw signal before testing.
    """
    LEVEL = "level"             # Raw value (no normalization)
    ZSCORE = "zscore"           # (x - mean) / std
    PERCENTILE = "percentile"   # Rolling percentile rank
    CHANGE = "change"           # First difference
    PCT_CHANGE = "pct_change"   # Percent change


@dataclass(frozen=True)
class HypothesisSpec:
    """
    Parent hypothesis specification - human-authored.

    Describes a market structure belief that can generate
    enumerated variants for testing.

    Attributes
    ----------
    family : str
        Category of hypothesis (e.g., 'term_structure_carry')
    name : str
        Unique identifier (e.g., 'cl_carry_slope_predicts_spread')
    economic_thesis : str
        Human-readable explanation of the market structure belief
    origin_node : str
        Starting point in market graph (e.g., 'CL_curve')
    propagation_path : tuple
        Path through market graph for signal propagation (Phase 2)
    allowed_expressions : frozenset
        Instruments where signal can be tested (e.g., {'CL1_CL2', 'flat_CL1'})
    sampling_clock : SamplingClock
        Native timescale for signal formation
    formation_window_days : tuple
        Allowed lookback windows (e.g., (5, 10, 20, 60))
    reaction_horizons : tuple
        Forward return horizons to test (e.g., (1, 3, 5, 10))
    normalization_types : tuple
        Allowed normalizations (e.g., (ZSCORE, PERCENTILE))
    target_type : TargetType
        What to predict (forward return, shock response, carry)
    direction : Direction
        Expected relationship (default: UNKNOWN - let scorer determine)
    param_grid : dict
        Additional enumeration parameters
    parent_hypothesis_id : int, optional
        ID of parent hypothesis if this was generated by expansion

    Example
    -------
    >>> H1 = HypothesisSpec(
    ...     family='term_structure_carry',
    ...     name='cl_carry_slope_predicts_spread',
    ...     economic_thesis='''
    ...         CL carry curve slope (PC2) measures storage pressure.
    ...         Test whether slope level predicts spread returns.
    ...     ''',
    ...     origin_node='CL_curve',
    ...     allowed_expressions=frozenset({'CL1_CL2', 'CL1_CL3'}),
    ...     sampling_clock=SamplingClock.DAILY,
    ...     formation_window_days=(5, 10, 20, 60),
    ...     reaction_horizons=(1, 3, 5, 10),
    ...     normalization_types=(NormalizationType.ZSCORE,),
    ...     target_type=TargetType.FORWARD_RETURN,
    ...     direction=Direction.UNKNOWN,
    ... )
    """
    family: str
    name: str
    economic_thesis: str
    origin_node: str
    propagation_path: Tuple[str, ...] = field(default_factory=tuple)
    allowed_expressions: FrozenSet[str] = field(default_factory=frozenset)
    sampling_clock: SamplingClock = SamplingClock.DAILY
    formation_window_days: Tuple[int, ...] = (10, 20, 60)
    reaction_horizons: Tuple[int, ...] = (1, 3, 5, 10)
    normalization_types: Tuple[NormalizationType, ...] = (NormalizationType.ZSCORE,)
    target_type: TargetType = TargetType.FORWARD_RETURN
    direction: Direction = Direction.UNKNOWN
    param_grid: Dict[str, List[Any]] = field(default_factory=dict)
    parent_hypothesis_id: Optional[int] = None

    def compute_hash(self) -> str:
        """
        Compute deterministic hash for deduplication.

        Hash is based on structural parameters that define unique hypotheses.
        """
        key = (
            self.family,
            self.origin_node,
            tuple(sorted(self.allowed_expressions)),
            self.target_type.value,
            self.sampling_clock.value,
            self.formation_window_days,
            self.reaction_horizons,
            tuple(n.value for n in self.normalization_types),
        )
        return hashlib.sha256(str(key).encode()).hexdigest()[:16]

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dictionary for database storage."""
        return {
            'family': self.family,
            'name': self.name,
            'economic_thesis': self.economic_thesis,
            'origin_node': self.origin_node,
            'propagation_path': list(self.propagation_path),
            'allowed_expressions': list(self.allowed_expressions),
            'sampling_clock': self.sampling_clock.value,
            'formation_window_days': list(self.formation_window_days),
            'reaction_horizons': list(self.reaction_horizons),
            'normalization_types': [n.value for n in self.normalization_types],
            'target_type': self.target_type.value,
            'direction': self.direction.value,
            'param_grid': self.param_grid,
            'parent_hypothesis_id': self.parent_hypothesis_id,
            'hypothesis_hash': self.compute_hash(),
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'HypothesisSpec':
        """Create from dictionary (database row)."""
        return cls(
            family=data['family'],
            name=data['name'],
            economic_thesis=data['economic_thesis'],
            origin_node=data['origin_node'],
            propagation_path=tuple(data.get('propagation_path', [])),
            allowed_expressions=frozenset(data['allowed_expressions']),
            sampling_clock=SamplingClock(data['sampling_clock']),
            formation_window_days=tuple(data['formation_window_days']),
            reaction_horizons=tuple(data['reaction_horizons']),
            normalization_types=tuple(
                NormalizationType(n) for n in data.get('normalization_types', ['zscore'])
            ),
            target_type=TargetType(data.get('target_type', 'forward_return')),
            direction=Direction(data.get('direction', 'unknown')),
            param_grid=data.get('param_grid', {}),
            parent_hypothesis_id=data.get('parent_hypothesis_id'),
        )

    def enumerate_variants(self) -> List['VariantSpec']:
        """
        Generate all variant specifications for this hypothesis.

        Cartesian product of:
        - allowed_expressions
        - formation_window_days
        - reaction_horizons
        - normalization_types
        """
        variants = []
        for expression in sorted(self.allowed_expressions):
            for window in self.formation_window_days:
                for horizon in self.reaction_horizons:
                    for norm in self.normalization_types:
                        variant = VariantSpec(
                            hypothesis_name=self.name,
                            expression=expression,
                            formation_window=window,
                            reaction_horizon=horizon,
                            normalization=norm,
                            target_type=self.target_type,
                            direction=self.direction,
                            additional_params=self.param_grid,
                        )
                        variants.append(variant)
        return variants


@dataclass(frozen=True)
class VariantSpec:
    """
    Enumerated variant of a hypothesis.

    Represents a specific parameterization to test.

    Attributes
    ----------
    hypothesis_name : str
        Name of parent hypothesis
    expression : str
        Which instrument (e.g., 'CL1_CL2')
    formation_window : int
        Lookback days for signal formation
    reaction_horizon : int
        Forward return horizon
    normalization : NormalizationType
        How signal is normalized
    target_type : TargetType
        What to predict
    direction : Direction
        Expected relationship
    additional_params : dict
        Any additional parameters from hypothesis param_grid
    """
    hypothesis_name: str
    expression: str
    formation_window: int
    reaction_horizon: int
    normalization: NormalizationType
    target_type: TargetType = TargetType.FORWARD_RETURN
    direction: Direction = Direction.UNKNOWN
    additional_params: Dict[str, Any] = field(default_factory=dict)

    @property
    def param_hash(self) -> str:
        """Generate deterministic hash for deduplication."""
        params = {
            'expression': self.expression,
            'formation_window': self.formation_window,
            'reaction_horizon': self.reaction_horizon,
            'normalization': self.normalization.value,
            'target_type': self.target_type.value,
            **self.additional_params
        }
        param_str = json.dumps(params, sort_keys=True)
        return hashlib.sha256(param_str.encode()).hexdigest()

    def to_params_dict(self) -> Dict[str, Any]:
        """Get parameters as dictionary for database storage."""
        return {
            'expression': self.expression,
            'formation_window': self.formation_window,
            'reaction_horizon': self.reaction_horizon,
            'normalization': self.normalization.value,
            'target_type': self.target_type.value,
            'direction': self.direction.value,
            **self.additional_params
        }

    def __repr__(self) -> str:
        return (
            f"VariantSpec(expr={self.expression}, "
            f"window={self.formation_window}, "
            f"horizon={self.reaction_horizon}, "
            f"norm={self.normalization.value})"
        )
